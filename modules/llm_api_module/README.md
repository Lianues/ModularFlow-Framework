# é€šç”¨LLM APIæ¨¡å—

æœ¬æ¨¡å—æä¾›ç»Ÿä¸€çš„LLM APIè°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šä¸ªAPIæä¾›å•†ï¼ŒåŒ…æ‹¬OpenAIã€Anthropicã€Google Geminiç­‰ã€‚

## ç‰¹æ€§

- ğŸ”Œ **å¤šæä¾›å•†æ”¯æŒ**: æ”¯æŒOpenAIã€Anthropicã€Geminiå’Œè‡ªå®šä¹‰æä¾›å•†
- ğŸš€ **ç»Ÿä¸€æ¥å£**: æä¾›ä¸€è‡´çš„APIè°ƒç”¨ä½“éªŒï¼Œæ— è®ºä½¿ç”¨å“ªä¸ªæä¾›å•†
- ğŸ“¡ **æµå¼å“åº”**: æ”¯æŒå®æ—¶æµå¼æ–‡æœ¬ç”Ÿæˆ
- ğŸ”„ **è‡ªåŠ¨æ ¼å¼è½¬æ¢**: è‡ªåŠ¨å¤„ç†ä¸åŒæä¾›å•†çš„è¯·æ±‚/å“åº”æ ¼å¼
- ğŸ›¡ï¸ **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ğŸ“Š **ä½¿ç”¨ç»Ÿè®¡**: å†…ç½®ä»¤ç‰Œä½¿ç”¨ç»Ÿè®¡å’Œç›‘æ§
- ğŸ”§ **çµæ´»é…ç½®**: å¯è‡ªå®šä¹‰è¶…æ—¶ã€æ—¥å¿—ç­‰é…ç½®

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from modules.llm_api_module import LLMAPIManager, APIConfiguration

# åˆ›å»ºAPIé…ç½®
config = APIConfiguration(
    provider="openai",
    api_key="your-api-key",
    base_url="https://api.openai.com/v1",
    models=["gpt-4", "gpt-3.5-turbo"],
    enabled=True
)

# åˆ›å»ºAPIç®¡ç†å™¨
manager = LLMAPIManager(config)

# å‡†å¤‡æ¶ˆæ¯
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
    {"role": "user", "content": "ä½ å¥½"}
]

# è°ƒç”¨API
response = manager.call_api(
    messages=messages,
    model="gpt-4",
    max_tokens=2048,
    temperature=0.7
)

if response.success:
    print(response.content)
else:
    print(f"é”™è¯¯: {response.error}")
```

### æµå¼å“åº”

```python
# ä½¿ç”¨æµå¼å“åº”
response_stream = manager.call_api(
    messages=messages,
    model="gpt-4",
    stream=True
)

for chunk in response_stream:
    if chunk.content:
        print(chunk.content, end="", flush=True)
    if chunk.finish_reason:
        print(f"\nå®ŒæˆåŸå› : {chunk.finish_reason}")
        if chunk.usage:
            print(f"ä½¿ç”¨ç»Ÿè®¡: {chunk.usage}")
```

## æ”¯æŒçš„æä¾›å•†

### OpenAI
```python
config = APIConfiguration(
    provider="openai",
    api_key="sk-...",
    base_url="https://api.openai.com/v1",
    models=["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]
)
```

### Anthropic Claude
```python
config = APIConfiguration(
    provider="anthropic",
    api_key="sk-ant-...",
    base_url="https://api.anthropic.com/v1",
    models=["claude-3-opus-20240229", "claude-3-sonnet-20240229"]
)
```

### Google Gemini
```python
config = APIConfiguration(
    provider="gemini",
    api_key="AIza...",
    base_url="https://generativelanguage.googleapis.com/v1beta",
    models=["gemini-1.5-pro", "gemini-1.5-flash"]
)
```

### è‡ªå®šä¹‰æä¾›å•†
```python
config = APIConfiguration(
    provider="custom",
    api_key="your-key",
    base_url="https://your-api.com/v1",
    models=["your-model-1", "your-model-2"]
)
```

## APIé…ç½®é€‰é¡¹

| å‚æ•° | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|------|------|------|------|
| `provider` | str | æ˜¯ | æä¾›å•†åç§° (openai/anthropic/gemini/custom) |
| `api_key` | str | æ˜¯ | APIå¯†é’¥ |
| `base_url` | str | æ˜¯ | APIåŸºç¡€URL |
| `models` | List[str] | æ˜¯ | å¯ç”¨æ¨¡å‹åˆ—è¡¨ |
| `enabled` | bool | å¦ | æ˜¯å¦å¯ç”¨ (é»˜è®¤: True) |
| `timeout` | int | å¦ | è¯·æ±‚è¶…æ—¶æ—¶é—´ (é»˜è®¤: 60ç§’) |
| `connect_timeout` | int | å¦ | è¿æ¥è¶…æ—¶æ—¶é—´ (é»˜è®¤: 10ç§’) |
| `enable_logging` | bool | å¦ | æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿— (é»˜è®¤: False) |

## å“åº”æ ¼å¼

### éæµå¼å“åº”
```python
@dataclass
class APIResponse:
    success: bool                    # è¯·æ±‚æ˜¯å¦æˆåŠŸ
    content: str                     # ç”Ÿæˆçš„å†…å®¹
    error: Optional[str]             # é”™è¯¯ä¿¡æ¯
    usage: Optional[Dict[str, Any]]  # ä½¿ç”¨ç»Ÿè®¡
    response_time: float             # å“åº”æ—¶é—´
    model_used: Optional[str]        # ä½¿ç”¨çš„æ¨¡å‹
    finish_reason: Optional[str]     # å®ŒæˆåŸå› 
    raw_response: Optional[Dict]     # åŸå§‹å“åº”æ•°æ®
    provider: Optional[str]          # æä¾›å•†åç§°
```

### æµå¼å“åº”
```python
@dataclass
class StreamChunk:
    content: str                     # å†…å®¹ç‰‡æ®µ
    finish_reason: Optional[str]     # å®ŒæˆåŸå› 
    usage: Optional[Dict[str, Any]]  # ä½¿ç”¨ç»Ÿè®¡ï¼ˆæœ€åä¸€ä¸ªchunkï¼‰
```

## é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰å‚æ•°
```python
response = manager.call_api(
    messages=messages,
    model="gpt-4",
    temperature=0.8,
    top_p=0.9,
    max_tokens=4096,
    presence_penalty=0.1,
    frequency_penalty=0.1,
    stop_sequences=["[STOP]"]
)
```

### Geminiç‰¹æ€§
```python
response = manager.call_api(
    messages=messages,
    model="gemini-1.5-pro",
    disable_thinking=True  # ç¦ç”¨æ€è€ƒæ¨¡å¼
)
```

### Anthropicç‰¹æ€§
```python
response = manager.call_api(
    messages=messages,
    model="claude-3-opus-20240229",
    enable_thinking=True,          # å¯ç”¨æ‰©å±•æ€è€ƒ
    thinking_budget=16000,         # æ€è€ƒtokené¢„ç®—
    stop_sequences=["Human:", "AI:"]
)
```

## é”™è¯¯å¤„ç†

```python
try:
    response = manager.call_api(messages)
    if not response.success:
        if "rate limit" in response.error.lower():
            print("è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•")
        elif "invalid api key" in response.error.lower():
            print("APIå¯†é’¥æ— æ•ˆ")
        else:
            print(f"APIè°ƒç”¨å¤±è´¥: {response.error}")
except Exception as e:
    print(f"æ„å¤–é”™è¯¯: {e}")
```

## æœ€ä½³å®è·µ

1. **å¯†é’¥ç®¡ç†**: ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨APIå¯†é’¥ï¼Œä¸è¦ç¡¬ç¼–ç 
2. **é”™è¯¯é‡è¯•**: å¯¹ä¸´æ—¶ç½‘ç»œé”™è¯¯å®æ–½æŒ‡æ•°é€€é¿é‡è¯•
3. **æµå¼å“åº”**: å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆä½¿ç”¨æµå¼å“åº”æå‡ç”¨æˆ·ä½“éªŒ
4. **ä½¿ç”¨ç»Ÿè®¡**: ç›‘æ§tokenä½¿ç”¨é‡æ¥æ§åˆ¶æˆæœ¬
5. **è¶…æ—¶è®¾ç½®**: æ ¹æ®åº”ç”¨éœ€æ±‚åˆç†è®¾ç½®è¶…æ—¶æ—¶é—´
6. **æ—¥å¿—è®°å½•**: åœ¨å¼€å‘ç¯å¢ƒå¯ç”¨è¯¦ç»†æ—¥å¿—ä¾¿äºè°ƒè¯•

## è®¸å¯è¯

æœ¬æ¨¡å—é‡‡ç”¨MITè®¸å¯è¯ã€‚